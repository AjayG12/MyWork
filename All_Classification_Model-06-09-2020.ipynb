{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare all classification model\n",
    "# Logistic Regression\n",
    "# Decision Tree - 86%\n",
    "# Random Forest\n",
    "# SVM\n",
    "# KNN\n",
    "# Naive Bayes Theorem\n",
    "# Ensemble techniques - bagging and boosting \n",
    "# K-Fold method - applicable for all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case Study - \n",
    "import os\n",
    "os.chdir(\"C:\\\\Users\\\\Kumar Sundram\\\\Desktop\\\\my data\\\\DSP27\\\\Python\\\\DT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11021175</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>121315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17782313</td>\n",
       "      <td>Male</td>\n",
       "      <td>53</td>\n",
       "      <td>67214</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14603818</td>\n",
       "      <td>Female</td>\n",
       "      <td>59</td>\n",
       "      <td>111005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18188198</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>53414</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19357305</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>114285</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User ID  Gender  Age  EstimatedSalary  Purchased\n",
       "0  11021175    Male   42           121315          0\n",
       "1  17782313    Male   53            67214          0\n",
       "2  14603818  Female   59           111005          0\n",
       "3  18188198  Female   39            53414          0\n",
       "4  19357305    Male   39           114285          0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"Social_Network_Ads.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset.iloc[:,2:4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset.iloc[:,4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x= sc.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.17951354,  0.76103154],\n",
       "       [ 1.11315372, -1.14804259],\n",
       "       [ 1.622412  ,  0.39722026],\n",
       "       [-0.0751156 , -1.63500628],\n",
       "       [-0.0751156 ,  0.51296235],\n",
       "       [-0.0751156 ,  0.27205647],\n",
       "       [-1.68776681, -0.49988685],\n",
       "       [ 1.622412  ,  1.71449234],\n",
       "       [ 0.68877182, -0.67642883],\n",
       "       [ 0.17951354,  0.51010409],\n",
       "       [-0.66925025, -0.42211381],\n",
       "       [ 0.7736482 ,  0.48681452],\n",
       "       [ 1.28290648, -0.40397617],\n",
       "       [ 1.1980301 ,  1.66971285],\n",
       "       [ 1.45265924,  1.40703476],\n",
       "       [ 0.09463716,  1.23391563],\n",
       "       [ 0.94340096,  0.58523059],\n",
       "       [ 1.28290648, -0.95915007],\n",
       "       [ 0.3492663 ,  0.82945347],\n",
       "       [ 0.60389544,  0.48695567],\n",
       "       [ 1.02827734, -0.72004384],\n",
       "       [-1.68776681,  0.2258655 ],\n",
       "       [ 0.00976078, -1.41410826],\n",
       "       [ 1.02827734, -0.82625839],\n",
       "       [-1.00875577,  0.67023751],\n",
       "       [-1.51801405,  0.21697311],\n",
       "       [-1.26338491,  0.53166458],\n",
       "       [-0.15999198, -0.50532108],\n",
       "       [ 1.45265924,  0.50308193],\n",
       "       [ 1.45265924,  1.18754822],\n",
       "       [ 0.26438992,  0.24622622],\n",
       "       [-0.41462111, -0.53630326],\n",
       "       [-0.49949749, -0.12181953],\n",
       "       [-0.66925025, -1.08628994],\n",
       "       [ 1.28290648, -0.31060618],\n",
       "       [ 0.68877182, -1.6924186 ],\n",
       "       [-1.51801405, -1.6164452 ],\n",
       "       [ 0.17951354,  1.38254542],\n",
       "       [ 1.622412  ,  0.59020609],\n",
       "       [-1.43313767, -0.08695575],\n",
       "       [ 0.00976078,  1.17163368],\n",
       "       [-1.34826129,  0.69021008],\n",
       "       [ 0.85852458,  0.73844772],\n",
       "       [ 0.09463716,  0.48692038],\n",
       "       [ 1.02827734,  0.10366584],\n",
       "       [-0.49949749,  1.42961858],\n",
       "       [-1.68776681, -1.61168143],\n",
       "       [-1.26338491, -1.27151258],\n",
       "       [ 0.51901906, -1.54170686],\n",
       "       [ 1.53753562, -1.22433356],\n",
       "       [-0.15999198, -0.9753822 ],\n",
       "       [-1.60289043,  0.31433057],\n",
       "       [ 0.17951354,  0.73717738],\n",
       "       [-0.75412663, -1.11914235],\n",
       "       [-1.17850853, -0.68687385],\n",
       "       [ 0.60389544, -1.36901118],\n",
       "       [-0.75412663,  0.82532486],\n",
       "       [-0.32974473, -0.04302315],\n",
       "       [-1.26338491,  0.76053752],\n",
       "       [-1.00875577, -1.36223604],\n",
       "       [ 0.09463716,  0.27018625],\n",
       "       [-0.66925025, -0.44872037],\n",
       "       [ 1.11315372,  0.66325064],\n",
       "       [-0.15999198, -1.27052454],\n",
       "       [ 0.26438992, -1.63535915],\n",
       "       [-0.49949749, -0.39084932],\n",
       "       [-0.92387939, -0.12647744],\n",
       "       [ 0.60389544,  0.83065323],\n",
       "       [-0.75412663,  0.80718723],\n",
       "       [-0.75412663, -0.74287468],\n",
       "       [ 0.94340096,  1.50947357],\n",
       "       [ 1.622412  , -0.42670114],\n",
       "       [-0.92387939,  1.51166138],\n",
       "       [-1.26338491,  1.29902056],\n",
       "       [ 1.622412  ,  1.66244369],\n",
       "       [ 1.70728837,  1.50372175],\n",
       "       [-0.41462111, -1.06398842],\n",
       "       [-1.17850853, -1.1156842 ],\n",
       "       [-0.32974473,  0.37756527],\n",
       "       [-1.43313767, -0.57737759],\n",
       "       [ 1.53753562,  0.31157816],\n",
       "       [-0.83900301,  1.46935199],\n",
       "       [ 0.26438992,  1.75083818],\n",
       "       [ 1.36778286, -1.46213417],\n",
       "       [ 0.94340096,  0.10130159],\n",
       "       [-1.00875577, -1.57385352],\n",
       "       [ 0.09463716, -1.75283032],\n",
       "       [-0.49949749,  0.28073713],\n",
       "       [ 0.26438992,  0.53240561],\n",
       "       [ 0.60389544,  0.7790986 ],\n",
       "       [-0.49949749, -0.64597596],\n",
       "       [-0.49949749,  0.26785729],\n",
       "       [-1.17850853,  0.44012952],\n",
       "       [ 0.43414268, -0.14549725],\n",
       "       [ 1.45265924,  0.79060223],\n",
       "       [ 0.94340096, -0.14390933],\n",
       "       [-0.49949749,  1.52782293],\n",
       "       [ 1.622412  ,  1.34443522],\n",
       "       [-0.32974473, -1.67844485],\n",
       "       [-0.32974473, -0.70977526],\n",
       "       [-1.43313767,  0.48762613],\n",
       "       [ 1.1980301 ,  1.47609185],\n",
       "       [-0.24486835, -1.2051726 ],\n",
       "       [-0.32974473,  0.44256434],\n",
       "       [-0.49949749, -0.64407045],\n",
       "       [ 0.85852458,  1.74981485],\n",
       "       [ 0.00976078, -0.86242779],\n",
       "       [ 1.02827734,  0.0319622 ],\n",
       "       [ 0.09463716,  0.9514414 ],\n",
       "       [ 0.00976078,  0.29541661],\n",
       "       [ 0.7736482 ,  0.21189175],\n",
       "       [-1.68776681,  1.31338246],\n",
       "       [-1.34826129, -0.23664415],\n",
       "       [-1.00875577,  0.82483084],\n",
       "       [-1.68776681, -0.61319413],\n",
       "       [-1.43313767,  0.87102182],\n",
       "       [-0.0751156 , -0.79344127],\n",
       "       [ 0.17951354, -0.90639567],\n",
       "       [ 1.36778286, -1.15862875],\n",
       "       [-1.68776681,  1.27498996],\n",
       "       [ 1.36778286,  1.45618986],\n",
       "       [ 0.60389544, -1.54040123],\n",
       "       [ 1.1980301 ,  0.2189492 ],\n",
       "       [-0.75412663,  1.21662489],\n",
       "       [ 0.00976078,  1.43385305],\n",
       "       [ 1.02827734, -0.58570538],\n",
       "       [ 0.26438992,  1.21655432],\n",
       "       [ 0.43414268, -1.51347708],\n",
       "       [ 1.53753562, -0.74100445],\n",
       "       [-0.83900301, -0.51805977],\n",
       "       [-0.66925025,  0.92832827],\n",
       "       [-1.26338491,  0.50128228],\n",
       "       [ 0.68877182, -0.13734591],\n",
       "       [-0.58437387, -0.08078048],\n",
       "       [ 0.60389544,  1.24524283],\n",
       "       [-1.17850853,  0.68565803],\n",
       "       [ 1.1980301 ,  1.73933455],\n",
       "       [ 0.43414268, -0.6049722 ],\n",
       "       [ 1.53753562,  1.47693875],\n",
       "       [ 1.1980301 , -0.74294525],\n",
       "       [ 1.45265924,  0.87458583],\n",
       "       [ 0.85852458,  1.13493497],\n",
       "       [ 0.09463716, -1.43785656],\n",
       "       [ 0.51901906,  0.75185686],\n",
       "       [ 1.36778286,  1.06280788],\n",
       "       [-0.92387939, -0.24373689],\n",
       "       [-0.83900301, -1.65130898],\n",
       "       [-0.24486835,  0.38857489],\n",
       "       [-1.17850853,  0.65054724],\n",
       "       [-0.58437387,  0.44341123],\n",
       "       [ 0.09463716, -0.34695202],\n",
       "       [-0.83900301,  0.76089039],\n",
       "       [-0.41462111, -0.35697359],\n",
       "       [ 0.43414268,  0.03905493],\n",
       "       [ 0.26438992, -1.20665466],\n",
       "       [ 1.1980301 , -1.63175986],\n",
       "       [ 1.02827734, -1.66979948],\n",
       "       [ 1.53753562, -0.59858521],\n",
       "       [-0.83900301, -1.62671378],\n",
       "       [-1.51801405, -0.42497207],\n",
       "       [ 1.02827734, -0.37151193],\n",
       "       [ 0.51901906,  1.58124778],\n",
       "       [ 1.36778286,  0.03961953],\n",
       "       [-1.26338491,  1.56420405],\n",
       "       [-1.51801405, -0.24394861],\n",
       "       [ 0.17951354,  1.55640558],\n",
       "       [ 0.00976078,  1.23215127],\n",
       "       [ 1.53753562, -1.37508059],\n",
       "       [-0.15999198, -0.98243964],\n",
       "       [ 1.11315372,  0.62072954],\n",
       "       [-1.34826129, -1.40507473],\n",
       "       [ 0.43414268, -0.64103575],\n",
       "       [ 0.26438992,  0.18810817],\n",
       "       [ 1.1980301 , -0.36223139],\n",
       "       [-0.83900301,  0.04455974],\n",
       "       [-1.34826129, -1.26586663],\n",
       "       [ 0.26438992, -0.75448417],\n",
       "       [-0.49949749, -0.05615   ],\n",
       "       [-1.60289043, -1.14871304],\n",
       "       [-1.09363215, -1.40221646],\n",
       "       [ 0.26438992, -0.49600525],\n",
       "       [-0.75412663,  0.78626191],\n",
       "       [-0.41462111,  0.41129986],\n",
       "       [ 0.94340096,  0.44521088],\n",
       "       [-1.34826129,  1.60090277],\n",
       "       [ 1.11315372, -0.52829306],\n",
       "       [-1.34826129,  0.63696166],\n",
       "       [ 0.7736482 ,  0.85179028],\n",
       "       [-0.24486835,  0.38352881],\n",
       "       [-0.0751156 , -1.17524904],\n",
       "       [-1.00875577, -0.90583108],\n",
       "       [-0.49949749, -1.6487683 ],\n",
       "       [ 0.43414268, -1.38040896],\n",
       "       [-0.15999198, -0.13039432],\n",
       "       [-0.24486835,  0.56289378],\n",
       "       [-0.66925025,  1.75747218],\n",
       "       [-1.51801405, -1.58267533],\n",
       "       [ 1.45265924,  0.2493315 ],\n",
       "       [-1.17850853, -0.61869893],\n",
       "       [-0.49949749, -0.06207826],\n",
       "       [-0.49949749,  1.05536228],\n",
       "       [ 0.68877182, -1.60398881],\n",
       "       [ 0.09463716,  0.54246247],\n",
       "       [ 0.60389544, -1.47141471],\n",
       "       [-0.66925025,  0.23916878],\n",
       "       [-0.75412663, -1.18174188],\n",
       "       [ 1.36778286,  0.50971593],\n",
       "       [-0.66925025, -0.21504837],\n",
       "       [-0.83900301, -0.31205295],\n",
       "       [-0.66925025, -0.42761861],\n",
       "       [-1.43313767, -1.49392796],\n",
       "       [-0.41462111,  1.3848038 ],\n",
       "       [ 1.28290648, -0.71722086],\n",
       "       [-1.43313767, -1.44142057],\n",
       "       [-0.66925025, -0.70352942],\n",
       "       [ 0.17951354, -0.91807574],\n",
       "       [ 0.43414268, -0.06715962],\n",
       "       [ 0.51901906,  0.89014749],\n",
       "       [-1.26338491,  0.95567587],\n",
       "       [-0.92387939,  1.06030249],\n",
       "       [ 0.3492663 ,  0.49380139],\n",
       "       [ 0.51901906,  1.43431178],\n",
       "       [-0.58437387, -0.10569326],\n",
       "       [-1.26338491, -0.92142803],\n",
       "       [ 1.1980301 ,  1.13017119],\n",
       "       [ 1.11315372,  0.54429741],\n",
       "       [-1.43313767,  1.1729746 ],\n",
       "       [ 1.28290648, -0.74100445],\n",
       "       [-1.17850853,  0.51370338],\n",
       "       [-0.92387939,  1.56716818],\n",
       "       [ 1.622412  , -0.91528805],\n",
       "       [ 0.43414268, -1.05975395],\n",
       "       [ 1.02827734,  0.11742785],\n",
       "       [-0.75412663,  0.73936518],\n",
       "       [ 0.26438992, -0.38753233],\n",
       "       [ 0.94340096,  1.60968929],\n",
       "       [-0.0751156 ,  0.02306982],\n",
       "       [-0.58437387,  1.18888914],\n",
       "       [-1.00875577, -0.7146449 ],\n",
       "       [ 0.17951354, -1.43026981],\n",
       "       [-1.43313767, -1.41439055],\n",
       "       [-1.00875577, -0.12704204],\n",
       "       [ 1.45265924,  0.1744873 ],\n",
       "       [-0.15999198,  0.89903987],\n",
       "       [-1.26338491, -1.23209675],\n",
       "       [ 0.3492663 ,  1.67712317],\n",
       "       [-0.32974473, -1.68864286],\n",
       "       [ 0.51901906, -0.43082975],\n",
       "       [ 0.3492663 ,  0.82634819],\n",
       "       [ 1.53753562, -0.67110046],\n",
       "       [ 1.02827734, -1.33626464],\n",
       "       [ 1.28290648, -1.54587075],\n",
       "       [-0.32974473, -0.58492906],\n",
       "       [ 1.45265924, -1.32412583],\n",
       "       [-0.92387939, -0.49388802],\n",
       "       [-1.60289043, -0.2718608 ],\n",
       "       [ 1.53753562,  0.52721839],\n",
       "       [-1.26338491, -0.84672498],\n",
       "       [-0.0751156 ,  1.67119492],\n",
       "       [-1.09363215,  0.57873774],\n",
       "       [ 0.09463716, -0.83568008],\n",
       "       [-1.00875577,  1.41384519],\n",
       "       [ 0.94340096, -0.36639528],\n",
       "       [-0.83900301, -0.09754192],\n",
       "       [ 0.43414268, -0.57444875],\n",
       "       [ 0.26438992,  0.85231959],\n",
       "       [-0.75412663,  0.13852961],\n",
       "       [-1.26338491,  1.74797992],\n",
       "       [ 1.28290648,  0.06834333],\n",
       "       [-0.92387939, -0.54247853],\n",
       "       [ 1.622412  , -0.68274524],\n",
       "       [-0.41462111,  0.59525216],\n",
       "       [ 0.68877182, -1.27214775],\n",
       "       [-1.43313767,  0.90263917],\n",
       "       [-0.75412663,  0.54750855],\n",
       "       [-1.51801405, -1.67773911],\n",
       "       [ 1.28290648, -0.72156119],\n",
       "       [-1.34826129,  0.64920633],\n",
       "       [ 0.43414268,  0.6763422 ],\n",
       "       [-0.66925025,  1.62528624],\n",
       "       [-1.26338491, -0.34525823],\n",
       "       [ 1.45265924,  0.01569479],\n",
       "       [ 1.622412  , -1.71161485],\n",
       "       [ 1.622412  , -0.09701261],\n",
       "       [ 0.94340096,  0.74105897],\n",
       "       [ 0.60389544, -0.30930055],\n",
       "       [-0.15999198, -1.15986381],\n",
       "       [ 1.622412  , -1.5109364 ],\n",
       "       [ 1.70728837, -0.8820122 ],\n",
       "       [-1.34826129,  1.51014403],\n",
       "       [ 1.36778286, -0.98286309],\n",
       "       [-0.0751156 ,  1.37944015],\n",
       "       [-0.32974473, -0.93564878],\n",
       "       [-0.24486835,  1.59179866],\n",
       "       [-0.24486835,  1.33646031],\n",
       "       [-1.68776681, -1.33488844],\n",
       "       [ 1.622412  , -0.56545051],\n",
       "       [ 0.85852458,  0.53088826],\n",
       "       [ 0.94340096,  0.61508358],\n",
       "       [ 1.70728837, -1.25965608],\n",
       "       [-0.41462111, -1.5195112 ],\n",
       "       [ 1.45265924,  0.0593098 ],\n",
       "       [ 0.26438992, -0.87573107],\n",
       "       [-1.09363215, -1.00089486],\n",
       "       [-0.83900301,  1.10017705],\n",
       "       [-1.51801405,  0.3995845 ],\n",
       "       [ 1.45265924,  1.31955773],\n",
       "       [-0.24486835, -1.20725455],\n",
       "       [-1.26338491, -0.3685478 ],\n",
       "       [-1.43313767,  1.45213183],\n",
       "       [ 0.85852458,  1.29870298],\n",
       "       [ 1.1980301 , -0.85597023],\n",
       "       [ 1.02827734, -0.99930693],\n",
       "       [ 1.622412  , -0.63500163],\n",
       "       [ 0.3492663 , -0.13512281],\n",
       "       [ 0.60389544,  0.29262892],\n",
       "       [-0.92387939, -0.57120233],\n",
       "       [ 0.60389544,  0.65294677],\n",
       "       [ 1.02827734, -0.8786952 ],\n",
       "       [-1.26338491, -1.44262033],\n",
       "       [-0.15999198, -1.22715654],\n",
       "       [-1.68776681, -1.22768585],\n",
       "       [-1.51801405,  0.40978251],\n",
       "       [ 0.26438992, -0.30146679],\n",
       "       [ 0.09463716, -1.19860918],\n",
       "       [-0.66925025,  0.93757352],\n",
       "       [-1.43313767,  1.42626629],\n",
       "       [-1.00875577, -0.19440535],\n",
       "       [ 1.02827734,  0.89773425],\n",
       "       [ 1.02827734, -1.29310836],\n",
       "       [ 0.00976078,  0.25938836],\n",
       "       [ 0.7736482 , -1.42243604],\n",
       "       [-0.32974473,  1.23977331],\n",
       "       [-1.00875577, -1.44533745],\n",
       "       [-0.24486835,  1.59769163],\n",
       "       [-1.51801405,  1.63735447],\n",
       "       [-0.75412663,  0.97737751],\n",
       "       [-0.0751156 , -0.57684828],\n",
       "       [-1.60289043,  0.83672264],\n",
       "       [ 0.94340096, -1.25415127],\n",
       "       [ 0.7736482 ,  1.02042793],\n",
       "       [ 0.68877182,  0.71946319],\n",
       "       [-1.00875577, -0.68630925],\n",
       "       [-0.83900301,  0.16937065],\n",
       "       [-1.34826129,  1.37834624],\n",
       "       [ 0.17951354,  1.07893414],\n",
       "       [ 1.622412  ,  1.4190677 ],\n",
       "       [ 1.70728837, -0.94722299],\n",
       "       [ 0.94340096, -1.6816207 ],\n",
       "       [-0.32974473,  0.70679508],\n",
       "       [-0.58437387, -0.46336457],\n",
       "       [-0.92387939, -1.04983824],\n",
       "       [-1.60289043, -0.37313514],\n",
       "       [ 0.3492663 ,  1.53406876],\n",
       "       [-0.92387939,  1.09237858],\n",
       "       [ 1.622412  , -0.68909695],\n",
       "       [-1.00875577,  0.70587761],\n",
       "       [-1.60289043, -0.83649168],\n",
       "       [ 0.3492663 ,  1.63093219],\n",
       "       [-1.26338491, -0.70307069],\n",
       "       [ 0.26438992, -0.34462306],\n",
       "       [ 0.51901906,  1.68608613],\n",
       "       [-0.32974473, -1.38231447],\n",
       "       [ 0.26438992, -0.76397644],\n",
       "       [ 1.28290648, -0.64714044],\n",
       "       [-1.00875577, -1.01628009],\n",
       "       [ 0.85852458,  0.16051356],\n",
       "       [ 0.68877182,  0.99237458],\n",
       "       [-0.58437387,  0.93683249],\n",
       "       [-1.34826129,  0.39591463],\n",
       "       [ 1.11315372, -0.28505823],\n",
       "       [-0.0751156 , -0.29162165],\n",
       "       [-0.15999198, -0.73161805],\n",
       "       [ 0.60389544,  0.21136245],\n",
       "       [ 1.70728837,  1.75122634],\n",
       "       [-0.66925025,  1.1500379 ],\n",
       "       [ 1.28290648, -1.21688796],\n",
       "       [ 0.26438992,  0.75524444],\n",
       "       [ 1.28290648,  1.54945399],\n",
       "       [-0.0751156 ,  0.2866301 ],\n",
       "       [-0.41462111, -0.38890853],\n",
       "       [ 1.28290648, -0.76549379],\n",
       "       [-0.32974473, -1.45225375],\n",
       "       [-1.09363215, -1.33188902],\n",
       "       [ 0.94340096,  0.00468517],\n",
       "       [ 0.17951354, -0.96465488],\n",
       "       [ 0.60389544, -0.28325858],\n",
       "       [-0.49949749,  1.44772093],\n",
       "       [-0.41462111, -0.72699542],\n",
       "       [ 1.53753562,  1.01891058],\n",
       "       [-1.26338491,  1.00790096],\n",
       "       [-1.43313767, -0.94754058],\n",
       "       [ 1.45265924,  0.57238604],\n",
       "       [-1.00875577,  0.40314851],\n",
       "       [ 0.09463716,  0.28483045],\n",
       "       [-1.68776681,  1.4638119 ],\n",
       "       [ 0.85852458, -0.84337269],\n",
       "       [-1.26338491, -0.60652484],\n",
       "       [ 1.28290648,  1.69092048],\n",
       "       [ 1.1980301 ,  1.24294916]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and testing\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Model 1 - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classification Model 1 - Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logitReg = LogisticRegression()\n",
    "logitReg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logitReg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[64,  0],\n",
       "       [36,  0]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.625     , 0.625     , 0.625     , 0.625     , 0.6875    ,\n",
       "       0.625     , 0.625     , 0.66666667, 0.66666667, 0.66666667,\n",
       "       0.66666667, 0.66666667, 0.66666667, 0.64285714, 0.64285714,\n",
       "       0.64285714, 0.64285714, 0.64285714, 0.64285714, 0.64285714])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k-fold with logistic regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator=logitReg, X = x_train, y=y_train, cv=20)\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare all classification model\n",
    "# Logistic Regression - 68.75 % \n",
    "# Decision Tree - \n",
    "# Random Forest\n",
    "# SVM\n",
    "# KNN\n",
    "# Naive Bayes Theorem\n",
    "# Ensemble techniques - bagging and boosting \n",
    "# K-Fold method - applicable for all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Model 2 - Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier_dt = DecisionTreeClassifier(criterion = 'entropy')\n",
    "classifier_dt.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = classifier_dt.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48, 16],\n",
       "       [24, 12]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75      , 0.5       , 0.4375    , 0.5       , 0.625     ,\n",
       "       0.5       , 0.5625    , 0.26666667, 0.53333333, 0.73333333,\n",
       "       0.46666667, 0.46666667, 0.53333333, 0.57142857, 0.64285714,\n",
       "       0.35714286, 0.64285714, 0.57142857, 0.57142857, 0.5       ])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k-fold with decision tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator=classifier_dt, X = x_train, y=y_train, cv=20)\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare all classification model\n",
    "# Logistic Regression - 68.75 % \n",
    "# Decision Tree - 75 %\n",
    "# Random Forest\n",
    "# SVM\n",
    "# KNN\n",
    "# Naive Bayes Theorem\n",
    "# Ensemble techniques - bagging and boosting \n",
    "# K-Fold method - applicable for all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier_dt = DecisionTreeClassifier(criterion = 'gini')\n",
    "classifier_dt.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = classifier_dt.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[45, 19],\n",
       "       [23, 13]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.625     , 0.4375    , 0.5       , 0.5625    , 0.5625    ,\n",
       "       0.625     , 0.5       , 0.2       , 0.53333333, 0.8       ,\n",
       "       0.6       , 0.6       , 0.66666667, 0.64285714, 0.71428571,\n",
       "       0.42857143, 0.71428571, 0.64285714, 0.71428571, 0.5       ])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k-fold with decision tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator=classifier_dt, X = x_train, y=y_train, cv=20)\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare all classification model\n",
    "# Logistic Regression - 68.75 % \n",
    "# Decision Tree - 80%\n",
    "    # entropy = 75 %\n",
    "    # gini - 80%\n",
    "# Random Forest\n",
    "# SVM\n",
    "# KNN\n",
    "# Naive Bayes Theorem\n",
    "# Ensemble techniques - bagging and boosting \n",
    "# K-Fold method - applicable for all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Model 3 - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier_rf = RandomForestClassifier(n_estimators = 10, criterion = 'entropy')\n",
    "classifier_rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = classifier_rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[52, 12],\n",
       "       [28,  8]], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.625     , 0.5       , 0.375     , 0.5       , 0.5625    ,\n",
       "       0.625     , 0.6875    , 0.66666667, 0.53333333, 0.8       ,\n",
       "       0.6       , 0.6       , 0.53333333, 0.71428571, 0.71428571,\n",
       "       0.5       , 0.57142857, 0.71428571, 0.5       , 0.35714286])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k-fold with random forest\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator=classifier_rf, X = x_train, y=y_train, cv=20)\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare all classification model\n",
    "# Logistic Regression - 68.75 % \n",
    "# Decision Tree - 80%\n",
    "    # entropy = 75 %\n",
    "    # gini - 80%\n",
    "# Random Forest - 80%\n",
    "# SVM\n",
    "# KNN\n",
    "# Naive Bayes Theorem\n",
    "# Ensemble techniques - bagging and boosting \n",
    "# PCA - Principal Componant analysis - \n",
    "# K-Fold method - applicable for all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10000, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier_rf = RandomForestClassifier(n_estimators = 10000, criterion = 'gini')\n",
    "classifier_rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = classifier_rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[53, 11],\n",
       "       [29,  7]], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-ef1dd4636406>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# k-fold with random forest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0maccuracies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclassifier_rf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0maccuracies\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    400\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m                                 error_score=error_score)\n\u001b[0m\u001b[0;32m    403\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    238\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m             error_score=error_score)\n\u001b[1;32m--> 240\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 920\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    921\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    317\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_more_estimators\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m                 tree = self._make_estimator(append=False,\n\u001b[1;32m--> 319\u001b[1;33m                                             random_state=random_state)\n\u001b[0m\u001b[0;32m    320\u001b[0m                 \u001b[0mtrees\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\base.py\u001b[0m in \u001b[0;36m_make_estimator\u001b[1;34m(self, append, random_state)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m             \u001b[0m_set_random_states\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mappend\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\base.py\u001b[0m in \u001b[0;36m_set_random_states\u001b[1;34m(estimator, random_state)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mto_set\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mto_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mset_params\u001b[1;34m(self, **params)\u001b[0m\n\u001b[0;32m    204\u001b[0m             \u001b[1;31m# Simple optimization to gain speed (inspect is slow)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m         \u001b[0mvalid_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[0mnested_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# grouped by prefix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mget_params\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    181\u001b[0m         \"\"\"\n\u001b[0;32m    182\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_param_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdeep\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'get_params'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_get_param_names\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[1;31m# introspect the constructor arguments to find the model parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[1;31m# to represent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m         \u001b[0minit_signature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m         \u001b[1;31m# Consider the constructor parameters excluding 'self'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m         parameters = [p for p in init_signature.parameters.values()\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\inspect.py\u001b[0m in \u001b[0;36msignature\u001b[1;34m(obj, follow_wrapped)\u001b[0m\n\u001b[0;32m   3081\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollow_wrapped\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3082\u001b[0m     \u001b[1;34m\"\"\"Get a signature object for the passed callable.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3083\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mSignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollow_wrapped\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow_wrapped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3084\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3085\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\inspect.py\u001b[0m in \u001b[0;36mfrom_callable\u001b[1;34m(cls, obj, follow_wrapped)\u001b[0m\n\u001b[0;32m   2831\u001b[0m         \u001b[1;34m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2832\u001b[0m         return _signature_from_callable(obj, sigcls=cls,\n\u001b[1;32m-> 2833\u001b[1;33m                                         follow_wrapper_chains=follow_wrapped)\n\u001b[0m\u001b[0;32m   2834\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2835\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\inspect.py\u001b[0m in \u001b[0;36m_signature_from_callable\u001b[1;34m(obj, follow_wrapper_chains, skip_bound_arg, sigcls)\u001b[0m\n\u001b[0;32m   2282\u001b[0m         \u001b[1;31m# If it's a pure Python function, or an object that is duck type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2283\u001b[0m         \u001b[1;31m# of a Python function (Cython functions, for instance), then:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2284\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_signature_from_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msigcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2286\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_signature_is_builtin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\inspect.py\u001b[0m in \u001b[0;36m_signature_from_function\u001b[1;34m(cls, func)\u001b[0m\n\u001b[0;32m   2150\u001b[0m     \u001b[0mnon_default_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpos_count\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mpos_default_count\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2151\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnon_default_count\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2152\u001b[1;33m         \u001b[0mannotation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mannotations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_empty\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2153\u001b[0m         parameters.append(Parameter(name, annotation=annotation,\n\u001b[0;32m   2154\u001b[0m                                     kind=_POSITIONAL_OR_KEYWORD))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# k-fold with random forest\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator=classifier_rf, X = x_train, y=y_train, cv=20)\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare all classification model\n",
    "# Logistic Regression - 68.75 % \n",
    "# Decision Tree - 80%\n",
    "    # entropy = 75 %\n",
    "    # gini - 80%\n",
    "# Random Forest - 80%\n",
    "    # tree = 500 - 92.8% \n",
    "# SVM\n",
    "# KNN\n",
    "# Naive Bayes Theorem\n",
    "# Ensemble techniques - bagging and boosting \n",
    "# PCA - Principal Componant analysis - \n",
    "# K-Fold method - applicable for all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Model 4 - Support Vetor Machine (kernel = Sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='sigmoid', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier_svm_sigmoid = SVC(kernel='sigmoid')\n",
    "classifier_svm_sigmoid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3=classifier_svm_sigmoid.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[64,  0],\n",
       "       [36,  0]], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.625     , 0.625     , 0.625     , 0.625     , 0.3125    ,\n",
       "       0.625     , 0.625     , 0.66666667, 0.66666667, 0.66666667,\n",
       "       0.66666667, 0.66666667, 0.66666667, 0.64285714, 0.64285714,\n",
       "       0.64285714, 0.64285714, 0.64285714, 0.64285714, 0.5       ])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k-fold with random forest\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator=classifier_svm_sigmoid, X = x_train, y=y_train, cv=20)\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare all classification model\n",
    "# Logistic Regression - 68.75 % \n",
    "# Decision Tree - 80%\n",
    "    # entropy = 75 %\n",
    "    # gini - 80%\n",
    "# Random Forest - 80%\n",
    "    # tree = 500 - 92.8% \n",
    "# SVM -\n",
    "    # sigmoid - 66.6%\n",
    "    # rbf - \n",
    "# KNN\n",
    "# Naive Bayes Theorem\n",
    "# Ensemble techniques - bagging and boosting \n",
    "# PCA - Principal Componant analysis - \n",
    "# K-Fold method - applicable for all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "classifier_svm_sigmoid = SVC(kernel='rbf')\n",
    "classifier_svm_sigmoid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3=classifier_svm_sigmoid.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[64,  0],\n",
       "       [36,  0]], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.625     , 0.625     , 0.625     , 0.625     , 0.3125    ,\n",
       "       0.625     , 0.625     , 0.66666667, 0.66666667, 0.66666667,\n",
       "       0.66666667, 0.66666667, 0.66666667, 0.64285714, 0.64285714,\n",
       "       0.64285714, 0.64285714, 0.64285714, 0.64285714, 0.5       ])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k-fold with SVM\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator=classifier_svm_sigmoid, X = x_train, y=y_train, cv=20)\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare all classification model\n",
    "# Logistic Regression - 68.75 % \n",
    "# Decision Tree - 80%\n",
    "    # entropy = 75 %\n",
    "    # gini - 80%\n",
    "# Random Forest - 80%\n",
    "    # tree = 500 - 92.8% \n",
    "# SVM -\n",
    "    # sigmoid - 66.6%\n",
    "    # rbf - 66.6%\n",
    "# KNN\n",
    "# Naive Bayes Theorem\n",
    "# Ensemble techniques - bagging and boosting \n",
    "# PCA - Principal Componant analysis - \n",
    "# K-Fold method - applicable for all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Model 5 - K Nearest Neighbour (KNN Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=7, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier_knn = KNeighborsClassifier(n_neighbors = 7, metric = 'minkowski', p=2)\n",
    "classifier_knn.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred4 = classifier_knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[55,  9],\n",
       "       [32,  4]], dtype=int64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5625    , 0.5       , 0.5625    , 0.5625    , 0.4375    ,\n",
       "       0.625     , 0.625     , 0.66666667, 0.66666667, 0.66666667,\n",
       "       0.6       , 0.53333333, 0.73333333, 0.64285714, 0.71428571,\n",
       "       0.5       , 0.64285714, 0.71428571, 0.64285714, 0.21428571])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k-fold with KNN\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator=classifier_knn, X = x_train, y=y_train, cv=20)\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare all classification model\n",
    "# Logistic Regression - 68.75 % \n",
    "# Decision Tree - 80%\n",
    "    # entropy = 75 %\n",
    "    # gini - 80%\n",
    "# Random Forest - 80%\n",
    "    # tree = 500 - 92.8% \n",
    "# SVM -\n",
    "    # sigmoid - 66.6%\n",
    "    # rbf - 66.6%\n",
    "# KNN - 73.3 %\n",
    "# Naive Bayes Theorem - adhoc project\n",
    "# Ensemble techniques - \n",
    "    # bagging  \n",
    "    # boosting \n",
    "# PCA - Principal Componant analysis - \n",
    "# K-Fold method - applicable for all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Model 6 - Naive Bayes Theorem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier_nvt = GaussianNB()\n",
    "classifier_nvt.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred5 = classifier_nvt.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[64,  0],\n",
       "       [34,  2]], dtype=int64)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.625     , 0.625     , 0.625     , 0.625     , 0.625     ,\n",
       "       0.625     , 0.625     , 0.66666667, 0.66666667, 0.66666667,\n",
       "       0.66666667, 0.6       , 0.66666667, 0.64285714, 0.64285714,\n",
       "       0.64285714, 0.64285714, 0.64285714, 0.64285714, 0.64285714])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k-fold with Naive Bayes Theorem\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator=classifier_nvt, X = x_train, y=y_train, cv=20)\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare all classification model\n",
    "# Logistic Regression - 68.75 % \n",
    "# Decision Tree - 80%\n",
    "    # entropy = 75 %\n",
    "    # gini - 80%\n",
    "# Random Forest - 80%\n",
    "    # tree = 500 - 92.8% \n",
    "# SVM -\n",
    "    # sigmoid - 66.6%\n",
    "    # rbf - 66.6%\n",
    "# KNN - 73.3 %\n",
    "# Naive Bayes Theorem - adhoc project - 66.6 %\n",
    "# Ensemble techniques - \n",
    "    # bagging  \n",
    "    # boosting \n",
    "# PCA - Principal Componant analysis - \n",
    "# K-Fold method - applicable for all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging_Classifier_Model-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
       "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
       "         n_estimators=500, n_jobs=None, oob_score=False, random_state=None,\n",
       "         verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "classifier_bagging = BaggingClassifier(n_estimators=500, max_samples=1.0)\n",
    "classifier_bagging.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred6 = classifier_bagging.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[54, 10],\n",
       "       [27,  9]], dtype=int64)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5625    , 0.375     , 0.5       , 0.5625    , 0.5       ,\n",
       "       0.625     , 0.6875    , 0.4       , 0.6       , 0.66666667,\n",
       "       0.66666667, 0.66666667, 0.86666667, 0.78571429, 0.64285714,\n",
       "       0.42857143, 0.64285714, 0.64285714, 0.57142857, 0.5       ])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k-fold with Bagging method\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator=classifier_bagging, X = x_train, y=y_train, cv=20)\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare all classification model\n",
    "# Logistic Regression - 68.75 % \n",
    "# Decision Tree - 80%\n",
    "    # entropy = 75 %\n",
    "    # gini - 80%\n",
    "# Random Forest - 80%\n",
    "    # tree = 500 - 92.8% \n",
    "# SVM -\n",
    "    # sigmoid - 66.6%\n",
    "    # rbf - 66.6%\n",
    "# KNN - 73.3 %\n",
    "# Naive Bayes Theorem - adhoc project - 66.6 %\n",
    "# Ensemble techniques - \n",
    "    # bagging - 86.6%\n",
    "    # boosting \n",
    "# PCA - Principal Componant analysis - \n",
    "# K-Fold method - applicable for all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost_Classifier_Model-8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=1, missing=None,\n",
       "       n_estimators=100, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=None,\n",
       "       subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "classifier_xgb = XGBClassifier()\n",
    "classifier_xgb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred7 = classifier_xgb.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[59,  5],\n",
       "       [29,  7]], dtype=int64)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.625     , 0.4375    , 0.5625    , 0.5       , 0.3125    ,\n",
       "       0.625     , 0.75      , 0.53333333, 0.6       , 0.73333333,\n",
       "       0.6       , 0.6       , 0.8       , 0.71428571, 0.71428571,\n",
       "       0.42857143, 0.71428571, 0.57142857, 0.64285714, 0.42857143])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k-fold with XGBoost method\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator=classifier_xgb, X = x_train, y=y_train, cv=20)\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare all classification model\n",
    "# Logistic Regression - 68.75 % \n",
    "# Decision Tree - 80%\n",
    "    # entropy = 75 %\n",
    "    # gini - 80%\n",
    "# Random Forest - 80%\n",
    "    # tree = 500 - 92.8% \n",
    "# SVM -\n",
    "    # sigmoid - 66.6%\n",
    "    # rbf - 66.6%\n",
    "# KNN - 73.3 %\n",
    "# Naive Bayes Theorem - adhoc project - 66.6 %\n",
    "# Ensemble techniques - \n",
    "    # bagging - 86.6%\n",
    "    # boosting - 80 %\n",
    "# PCA - Principal Componant analysis - \n",
    "# K-Fold method - applicable for all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel PCA (Principal Component Analysis) - Model 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "classifier_pca = KernelPCA(n_components = 2, kernel ='rbf')\n",
    "x_train = classifier_pca.fit_transform(x_train)\n",
    "x_test = classifier_pca.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=0, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classification Model 1 - Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logitReg = LogisticRegression(random_state=0)\n",
    "logitReg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred8 = logitReg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[64,  0],\n",
       "       [36,  0]], dtype=int64)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Kumar Sundram\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.625     , 0.625     , 0.625     , 0.625     , 0.625     ,\n",
       "       0.625     , 0.625     , 0.66666667, 0.66666667, 0.66666667,\n",
       "       0.66666667, 0.66666667, 0.66666667, 0.64285714, 0.64285714,\n",
       "       0.64285714, 0.64285714, 0.64285714, 0.64285714, 0.64285714])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k-fold with PCA-Logistic\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator=logitReg, X = x_train, y=y_train, cv=20)\n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare all classification model\n",
    "# Logistic Regression - 68.75 % \n",
    "# Decision Tree - 80%\n",
    "    # entropy = 75 %\n",
    "    # gini - 80%\n",
    "# Random Forest - 80%\n",
    "    # tree = 500 - 92.8% \n",
    "# SVM -\n",
    "    # sigmoid - 66.6%\n",
    "    # rbf - 66.6%\n",
    "# KNN - 73.3 %\n",
    "# Naive Bayes Theorem - adhoc project - 66.6 %\n",
    "# Ensemble techniques - \n",
    "    # bagging - 86.6%\n",
    "    # boosting - 80 %\n",
    "# PCA - Principal Componant analysis with Logit Regression-  66.6%\n",
    "# K-Fold method - applicable for all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Validation \n",
    "## Random Forest - 92.8%\n",
    "### bagging - 86.6%\n",
    "#### boosting - 80 %\n",
    "##### Decision Tree - 80%\n",
    "###### KNN - 73.3 %\n",
    "___________________________________________________________________\n",
    "\n",
    "####### Logistic Regression - 68.75 % \n",
    "######## PCA - Principal Componant analysis with Logit Regression-  66.6%\n",
    "######## Naive Bayes Theorem - adhoc project - 66.6 %\n",
    "######## SVM - 66.6 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
